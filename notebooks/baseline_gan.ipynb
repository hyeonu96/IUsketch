{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IU Sketch Baseline 코드  \n",
    " - python모듈 설치 코드는 처음 한번 실행해주세요.     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imageio\n",
    "# !pip install imageio --upgrade\n",
    "# !pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 path 설정.\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(os.getcwd()  , '..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베이스 라인 코드.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import ThresholdedReLU\n",
    "\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import apps.config_env as cfg\n",
    "\n",
    "from classes.image_frame import ImgFrame\n",
    "from classes.video_clip import VideoClip\n",
    "from models.dataset_generator import DataSetGenerator\n",
    "from models.draw_generator import DrawGenerator\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from models.layer_conv import Conv2Plus1D, TConv2Plus1D\n",
    "# from models.layer_encoder import Encoder5D, Decoder5D\n",
    "# from models.layer_lstm import ConvLstmSeries\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(tf.__version__)\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 디렉토리 없으면 생성.\n",
    "\n",
    "# 학습용 raw_clip(gif) 파일 위치.\n",
    "if not os.path.exists(cfg.RAW_CLIP_PATH):\n",
    "    os.mkdir(cfg.RAW_CLIP_PATH)\n",
    "\n",
    "# 모델 저장 위치\n",
    "if not os.path.exists(cfg.MODEL_SAVE_PATH):\n",
    "    os.mkdir(cfg.MODEL_SAVE_PATH)\n",
    "\n",
    "# 임시 데이터 저장 위치\n",
    "if not os.path.exists(cfg.TEMP_DATA_PATH):\n",
    "    os.mkdir(cfg.TEMP_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 15    # matlab 차트의 기본 크기를 15,6으로 지정해 줍니다.\n",
    "\n",
    "def plot_history(history):\n",
    "    \n",
    "    # summarize history for loss  \n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history['tgen_loss'])  \n",
    "    plt.plot(history['tdisc_loss'])  \n",
    "    plt.plot(history['tl1_loss'])  \n",
    "    plt.plot(history['vgen_loss'])  \n",
    "    plt.plot(history['vdisc_loss'])  \n",
    "    plt.plot(history['vl1_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('batch iters')  \n",
    "    plt.legend(['tgen_loss', 'tdisc_loss', 'tl1_loss', 'vgen_loss', 'vdisc_loss', 'vl1_loss'], loc='upper right')  \n",
    "\n",
    "    # summarize history for accuracy  \n",
    "    # plt.subplot(212)  \n",
    "    # plt.plot(history['fake_accuracy'])  \n",
    "    # plt.plot(history['real_accuracy'])  \n",
    "    # plt.title('discriminator accuracy')  \n",
    "    # plt.ylabel('accuracy')  \n",
    "    # plt.xlabel('batch iters')  \n",
    "    # plt.legend(['fake_accuracy', 'real_accuracy'], loc='upper right')  \n",
    "    \n",
    "    # training_history 디렉토리에 epoch별로 그래프를 이미지 파일로 저장합니다.\n",
    "    # plt.savefig(os.path.join(history_path, 'train_history_{:04d}.png'.format(epoch)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arry5d_to_img(arry5d, save_as='', threshold=0.0):\n",
    "    frmimg_cnt = arry5d.shape[1]\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = frmimg_cnt, figsize=(15, 3))\n",
    "\n",
    "    for idx, num in enumerate(range(0, frmimg_cnt)):\n",
    "        frm = ImgFrame(img=arry5d[0][idx][:, :, :], do_norm=False)\n",
    "        min_val = np.min(frm.arry)\n",
    "        max_val = np.max(frm.arry)\n",
    "        frm.arry = (frm.arry - min_val) / (max_val - min_val)\n",
    "\n",
    "        min_val = np.min(frm.arry)\n",
    "        max_val = np.max(frm.arry)\n",
    "        # print(\"min,max: \", np.min(frm.arry), np.max(frm.arry))\n",
    "\n",
    "        if threshold > 0.0:\n",
    "            frm.threshold(threshold=threshold)\n",
    "\n",
    "        img = frm.to_flatten_image()\n",
    "        axes[idx].xaxis.set_major_locator(MultipleLocator(8))\n",
    "        axes[idx].yaxis.set_major_locator(MultipleLocator(8))\n",
    "        axes[idx].grid(visible=True, color='pink', alpha=0.5)\n",
    "        \n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_imgs(arrys=[], save_path=\"\", channel=-1):\n",
    "    frmimg_cnt = arrys[0].shape[1]\n",
    "    fig, axes = plt.subplots(nrows = len(arrys), ncols = frmimg_cnt, figsize=(15, 5))\n",
    "        \n",
    "    for i, arry in enumerate(arrys):\n",
    "        for idx, num in enumerate(range(0, frmimg_cnt)):\n",
    "            frm = ImgFrame(img=arry[0, idx, ...], do_norm=False)\n",
    "            min_val = np.min(frm.arry)\n",
    "            max_val = np.max(frm.arry)\n",
    "            frm.arry = (frm.arry - min_val) / (max_val - min_val)\n",
    "\n",
    "            min_val = np.min(frm.arry)\n",
    "            max_val = np.max(frm.arry)\n",
    "            # print(\"min,max: \", np.min(frm.arry), np.max(frm.arry))\n",
    "            \n",
    "            if channel != -1 and i < channel:\n",
    "                img = frm.to_image(channel=i)\n",
    "                axes[i][idx].imshow(img, cmap='gray')\n",
    "            else:\n",
    "                img = frm.to_flatten_image()\n",
    "                axes[i][idx].imshow(img, cmap='gray')\n",
    "                \n",
    "            axes[i][idx].xaxis.set_major_locator(MultipleLocator(8))\n",
    "            axes[i][idx].yaxis.set_major_locator(MultipleLocator(8))\n",
    "            axes[i][idx].grid(visible=True, color='pink', alpha=0.5)\n",
    "\n",
    "    if save_path != \"\":\n",
    "        plt.savefig(save_path)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w, img_h = 64, 64 #cfg.DATA_IMG_W, cfg.DATA_IMG_H\n",
    "input_channel = 2 # for draw_generator, default : 1\n",
    "batch_size = 5 #cfg.DATA_BATCH_SIZE\n",
    "time_steps = 5 # cfg.DATA_TIME_STEP\n",
    "stack_step = 10\n",
    "enc_blk_count = 5  # 3 - 7\n",
    "disc_blk_count = 3 # \n",
    "EPOCHS = 100\n",
    "\n",
    "enc_filters = [64,128,256,512,512,512,512,512]\n",
    "dec_filters = [512,512,512,512,256,128,64]\n",
    "use_conv2n1 = False\n",
    "train_lamda = 100\n",
    "\n",
    "# discriminator augmentation\n",
    "use_ada = True\n",
    "ada_p = 0.8\n",
    "ada_lamda1 = 10\n",
    "ada_lamda2 = 10\n",
    "\n",
    "# dataset 설정.\n",
    "data_seq_type = 'aforward'  # 'all', 'rest', 'arandom', 'aforward', 'forward', 'reverse', 'random'\n",
    "data_label_type = '1step'   # 'all', 'rest', 'same', '1step'\n",
    "stakced = True\n",
    "overlap = False\n",
    "fill_box = False\n",
    "invert = True\n",
    "\n",
    "save_load_prefix = \"test_00\"\n",
    "save_load_preload = True\n",
    "save_load_interval = 10\n",
    "\n",
    "# 전체 raw_clip 랜덤한 이미지 목록을 가져옴.\n",
    "img_list = glob.glob(os.path.join(cfg.RAW_CLIP_PATH, \"*.gif\"))\n",
    "random.shuffle(img_list)\n",
    "\n",
    "# 이미지 목록을 train/validation용으로 9:1로 나눔.\n",
    "train_val_ratio = 0.9\n",
    "train_img_cnt = int(len(img_list) * train_val_ratio)\n",
    "train_img_list = img_list[:train_img_cnt]\n",
    "val_img_list = img_list[train_img_cnt:]\n",
    "\n",
    "# train/validation용 generator를 생성.\n",
    "# tdgen = DataSetGenerator(imgs=train_img_list, batch_size=batch_size, \n",
    "#                          time_step=time_steps, imgw=img_w, imgh=img_h, \n",
    "#                          seq_type=data_seq_type, label_type=data_label_type,\n",
    "#                          stacked=stakced, overlap=overlap, fill_box=fill_box, invert=invert)\n",
    "\n",
    "# vdgen = DataSetGenerator(imgs=val_img_list, batch_size=batch_size, \n",
    "#                          time_step=time_steps, imgw=img_w, imgh=img_h, \n",
    "#                          seq_type=data_seq_type, label_type=data_label_type,\n",
    "#                          stacked=stakced, overlap=overlap, fill_box=fill_box, invert=invert)\n",
    "\n",
    "tdgen = DrawGenerator(imgs=train_img_list, batch_size=batch_size, stack_step=stack_step,\n",
    "                         time_step=time_steps, imgw=img_w, imgh=img_h, fill_box=fill_box, invert=invert)\n",
    "\n",
    "vdgen = DrawGenerator(imgs=val_img_list, batch_size=batch_size, stack_step=stack_step,\n",
    "                         time_step=time_steps, imgw=img_w, imgh=img_h, fill_box=fill_box, invert=invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample data\n",
    "it = iter(tdgen)\n",
    "x, y = next(it)\n",
    "\n",
    "print(f\"train data : {len(train_img_list)}, val data : {len(val_img_list)}\")\n",
    "print(f\"x type: {x.shape}, y type: {y.shape}\")\n",
    "\n",
    "show_imgs(arrys=[x, x, y], channel=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeBlock(layers.Layer):\n",
    "    def __init__(self, n_filters, use_bn=True):\n",
    "        super(EncodeBlock, self).__init__()\n",
    "        self.use_bn = use_bn       \n",
    "        self.conv = layers.Conv3D(filters=n_filters,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, 2, 2),\n",
    "                    padding=\"same\")\n",
    "        self.conv2 = layers.Conv3D(filters=n_filters,\n",
    "                    kernel_size=(4, 1, 1),\n",
    "                    strides=1,\n",
    "                    padding=\"same\")        \n",
    "        self.batchnorm = layers.BatchNormalization()\n",
    "        self.lrelu= layers.LeakyReLU(0.2)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.conv(x, training=training)\n",
    "        if use_conv2n1:\n",
    "            x = self.conv2(x, training=training)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x, training=training)\n",
    "#         x = layers.Dropout(.5)(x, training=training)\n",
    "        return self.lrelu(x)\n",
    "\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, blk_cnt=5):\n",
    "        super(Encoder, self).__init__()\n",
    "#         filters = [64,128,256,512,512,512,512,512]\n",
    "        \n",
    "        self.blocks = []\n",
    "        for i in range(blk_cnt):\n",
    "            f = enc_filters[i]\n",
    "            if i == 0:\n",
    "                self.blocks.append(EncodeBlock(f, use_bn=False))\n",
    "            else:\n",
    "                self.blocks.append(EncodeBlock(f))\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        for block in self.blocks:\n",
    "            x = block(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def get_summary(self, input_shape=(None, img_w, img_h, input_channel)):\n",
    "        inputs = Input(input_shape)\n",
    "        return Model(inputs, self.call(inputs)).summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeBlock(layers.Layer):\n",
    "    def __init__(self, f, dropout=True):\n",
    "        super(DecodeBlock, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.Transconv = layers.Conv3DTranspose(filters=f,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, 2, 2),\n",
    "                    padding=\"same\")\n",
    "        self.Transconv2 = layers.Conv3DTranspose(filters=f, \n",
    "                    kernel_size=(4, 1, 1),\n",
    "                    strides=1,\n",
    "                    padding=\"same\")        \n",
    "        self.batchnorm = layers.BatchNormalization()\n",
    "#         self.relu = layers.ReLU()\n",
    "        self.relu = layers.LeakyReLU(0.2)\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        x = self.Transconv(x, training=training)\n",
    "        if use_conv2n1:\n",
    "            x = self.Transconv2(x, training=training)\n",
    "        x = self.batchnorm(x, training=training)\n",
    "        if self.dropout:\n",
    "            x = layers.Dropout(.5)(x, training=training)\n",
    "        return self.relu(x)\n",
    "\n",
    "    \n",
    "class Decoder(Model):\n",
    "    def __init__(self, blk_cnt=4):\n",
    "        super(Decoder, self).__init__()\n",
    "#         filters = [512,512,512,512,256,128,64]\n",
    "        \n",
    "        self.blocks = []\n",
    "        for i in range(blk_cnt):\n",
    "            f = dec_filters[i - blk_cnt]\n",
    "            if i < 3:\n",
    "                self.blocks.append(DecodeBlock(f))\n",
    "            else:\n",
    "                self.blocks.append(DecodeBlock(f, dropout=False))\n",
    "                \n",
    "        self.blocks.append(layers.Conv3DTranspose(filters=1,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, 2, 2),\n",
    "                    padding=\"same\"))\n",
    "        if use_conv2n1:\n",
    "            self.blocks.append(layers.Conv3DTranspose(filters=1,\n",
    "                    kernel_size=(4, 1, 1),\n",
    "                    strides=(1, 1, 1),\n",
    "                    padding=\"same\"))\n",
    "        self.out_relu = keras.activations.sigmoid\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.out_relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLstmSeries(Model):\n",
    "    '''\n",
    "        5-rank Colvolution LSTM\n",
    "    '''\n",
    "    def __init__(self, filter_cnt, final_filter_cnt, kernel_sizes):\n",
    "        \"\"\"\n",
    "            (b, t, h, w, c) -> (b, t, h/stride, w/stride, f)\n",
    "            A sequence of convolutional layers that first apply the convolution operation over the\n",
    "            spatial dimensions, and then the temporal dimension.\n",
    "        \"\"\"\n",
    "        super(ConvLstmSeries, self).__init__()\n",
    "        self.filter_cnt = filter_cnt\n",
    "        self.final_filter_cnt = final_filter_cnt\n",
    "        self.kernel_cnt = len(kernel_sizes)\n",
    "        self.lstms = []\n",
    "        self.bns = []\n",
    "        self.relus = []\n",
    "        self.out_conv = None\n",
    "\n",
    "        for kernel_size in kernel_sizes:\n",
    "            self.lstms.append(layers.ConvLSTM2D(\n",
    "                                filters=filter_cnt,\n",
    "                                kernel_size=kernel_size,\n",
    "                                padding=\"same\",\n",
    "                                return_sequences=True,\n",
    "                                #recurrent_activation='hard_sigmoid', # other nan... layers.ReLU(), #layers.LeakyReLU(0.2), #'hard_sigmoid',\n",
    "                                activation=layers.ReLU(), #layers.LeakyReLU(0.2), #\"relu\",\n",
    "                                kernel_regularizer=\"l2\",\n",
    "                                recurrent_regularizer=\"l2\",\n",
    "                                activity_regularizer=\"l2\",\n",
    "                            ))\n",
    "            self.bns.append(layers.BatchNormalization())\n",
    "            self.relus.append(layers.LeakyReLU(0.2)) #layers.ReLU()\n",
    "\n",
    "        # 출력의 channel depth를 맞춰주기 위해.\n",
    "        if final_filter_cnt > 0:\n",
    "            self.out_conv = layers.Conv3D(filters=final_filter_cnt,\n",
    "                    kernel_size=(1, 3, 3),\n",
    "                    strides=(1, 1, 1),\n",
    "                    padding=\"same\")\n",
    "            self.out_bn = layers.BatchNormalization()\n",
    "            self.out_relu = keras.activations.sigmoid # layers.LeakyReLU(0.2) # keras.activations.sigmoid # layers.ReLU()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for idx in range(self.kernel_cnt):\n",
    "            x = self.lstms[idx](x, training=training)\n",
    "            x = self.bns[idx](x, training=training)\n",
    "            x = layers.Dropout(.5)(x, training=training)\n",
    "            x = self.relus[idx](x)\n",
    "\n",
    "        if self.out_conv is not None:\n",
    "            x = self.out_conv(x, training=training)\n",
    "            x = self.out_bn(x, training=training)\n",
    "            x = layers.Dropout(.5)(x, training=training)\n",
    "            x = self.out_relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderGenerator(Model):\n",
    "    def __init__(self, blk_cnt=4):\n",
    "        super(EncoderDecoderGenerator, self).__init__()\n",
    "        self.encoder = Encoder(blk_cnt)\n",
    "        self.decoder = Decoder(blk_cnt-1)\n",
    "        \n",
    "        lstm_filters = enc_filters[blk_cnt-1]\n",
    "        self.lstms = ConvLstmSeries(lstm_filters, 0, [(5, 5), (3, 3), (1, 1)])\n",
    "#         self.lstms = ConvLstmSeries(lstm_filters, 1, [(5, 5), (3, 3), (1, 1)])\n",
    "    \n",
    "    ''' \n",
    "        아래와 같이 순서와 조합을 바꾸면 다른 모델이 됨.\n",
    "        이때 loss 및 save/load도 같이 바뀌므로 주의.\n",
    "            1. encoder - decoder(pix2pix gan model)\n",
    "            2. lstms\n",
    "            3. encoder(pretrained) - lstms - decoder(pretrained)\n",
    "            4. lstms(pre-trained) - encoder - decoder\n",
    "    '''\n",
    "    def call(self, x, training=False):\n",
    "        x = self.encoder(x, training=training)\n",
    "        # x = self.lstms(x, training=training)\n",
    "        x = self.decoder(x, training=training)\n",
    "        return x\n",
    "   \n",
    "    def get_summary(self, input_shape=(None, img_w, img_h, input_channel)):\n",
    "        inputs = Input(input_shape)\n",
    "        return Model(inputs, self.call(inputs)).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscBlock(layers.Layer):\n",
    "    def __init__(self, n_filters, stride=2, custom_pad=0, use_bn=True, act=True):\n",
    "        super(DiscBlock, self).__init__()\n",
    "        self.custom_pad = custom_pad\n",
    "        self.use_bn = use_bn\n",
    "        self.act = act\n",
    "        \n",
    "        # outputsize = (w - f + 2*p) / s + 1\n",
    "        if custom_pad > 0:\n",
    "            self.padding = layers.ZeroPadding3D(padding=(0,custom_pad,custom_pad))\n",
    "            self.conv = layers.Conv3D(filters=n_filters,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, stride, stride),\n",
    "                    padding=\"valid\")\n",
    "            self.conv2 = layers.Conv3D(filters=n_filters,\n",
    "                    kernel_size=(4, 1, 1),\n",
    "                    strides=(1, 1, 1),\n",
    "                    padding=\"valid\")\n",
    "        else:\n",
    "            self.conv = layers.Conv3D(filters=n_filters,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, stride, stride),\n",
    "                    padding=\"same\")\n",
    "            self.conv2 = layers.Conv3D(filters=n_filters,\n",
    "                    kernel_size=(4, 1, 1),\n",
    "                    strides=(1, 1, 1),\n",
    "                    padding=\"same\")\n",
    "        \n",
    "        self.batchnorm = layers.BatchNormalization() if use_bn else None\n",
    "        self.lrelu = layers.LeakyReLU(0.2) if act else None\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        if self.custom_pad:\n",
    "            x = self.padding(x)\n",
    "            x = self.conv(x, training=training)\n",
    "            if use_conv2n1:\n",
    "                x = self.conv2(x, training=training)\n",
    "        else:\n",
    "            x = self.conv(x, training=training)\n",
    "            if use_conv2n1:\n",
    "                x = self.conv2(x, training=training)\n",
    "            \n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x, training=training)\n",
    "\n",
    "        if training:\n",
    "            x = layers.Dropout(.5)(x, training=training)\n",
    "            \n",
    "        if self.act:\n",
    "            x = self.lrelu(x)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self, blk_cnt=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.concat = layers.Concatenate()\n",
    "\n",
    "        filters = [64,128,256,512,512,512]\n",
    "        self.blocks = []\n",
    "        for i in range(blk_cnt):\n",
    "            f = filters[i]\n",
    "            self.blocks.append(DiscBlock(\n",
    "                n_filters=f,\n",
    "                stride=2,\n",
    "                custom_pad=0,\n",
    "                use_bn=False if i==0 else True,\n",
    "                act=True\n",
    "            ))\n",
    "\n",
    "        self.blocks.append(DiscBlock(n_filters=512, stride=1, custom_pad=1, use_bn=True, act=True))\n",
    "        self.blocks.append(DiscBlock(n_filters=1, stride=1, custom_pad=1, use_bn=False, act=False))\n",
    "        self.sigmoid = layers.Activation(\"sigmoid\")\n",
    "\n",
    "\n",
    "    def call(self, x, y, training=False):\n",
    "        out = self.concat([x, y])\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            out = block(out, training=training)\n",
    "            \n",
    "        # if training:\n",
    "        #     out = layers.Dropout(.5)(out)\n",
    "                \n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "    def get_summary(self, x_shape=(None, img_w, img_h, 1), y_shape=(None, img_w, img_h, 1)):\n",
    "        x, y = Input(x_shape), Input(y_shape) \n",
    "        return Model((x, y), self.call(x, y)).summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    '''\n",
    "    모델학습 초기에 learning rate를 급격히 높였다가, \n",
    "    서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법\n",
    "    학습 초기에는 learning_rate가 step_num에 비례해서 증가하다가 이후로는 감소\n",
    "    '''\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADA(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ADA, self).__init__()\n",
    "        self.locked = False\n",
    "        self.p_list = []\n",
    "        self.aug_count = 3\n",
    "\n",
    "        self.flip = tf.image.flip_left_right\n",
    "        self.rot90 = tf.image.rot90\n",
    "        self.resize = tf.image.resize  # (sie, method, preserve_aspect_ratio)\n",
    "        self.cropnresize = tf.image.crop_and_resize #(image, boxes,box_indices,crop_size,method='bilinear',extrapolation_value=0.0,\n",
    "\n",
    "    def lock(self):\n",
    "        self.locked = True\n",
    "\n",
    "    def unlock(self):\n",
    "        self.locked = False\n",
    "\n",
    "    def is_locked(self):\n",
    "        return self.locked\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        x_shape = x.shape\n",
    "        x_batch_size =  x_shape[0]\n",
    "        x_step = x_shape[1]\n",
    "        x_batch = x_shape[0]*x_shape[1]\n",
    "        x_h, x_w = (x_shape[2], x_shape[3])\n",
    "        x_channel = x_shape[4]\n",
    "\n",
    "        # 5d tensor -> 4d tensor\n",
    "        x0 = tf.reshape(x, [x_batch, x_h, x_w, x_channel])\n",
    "        \n",
    "        if not self.is_locked():\n",
    "            self.p_list = []\n",
    "            for batch in range(x_batch):\n",
    "                batch_ps = [ random.random() for _ in range(self.aug_count) ]\n",
    "                self.p_list.append(batch_ps)\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for batch in range(x_batch):\n",
    "\n",
    "            batch_ps = self.p_list[batch]\n",
    "\n",
    "            x1 = x0[batch]\n",
    "\n",
    "            if batch_ps[0] > 0.5:\n",
    "                x1 = self.flip(x1)\n",
    "            if batch_ps[1] < 0.25:\n",
    "                x1 = self.rot90(x1, k=1)\n",
    "            elif batch_ps[1] < 0.5:\n",
    "                x1 = self.rot90(x1, k=2)\n",
    "            elif batch_ps[1] < 0.75:\n",
    "                x1 = self.rot90(x1, k=3)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "            x1 = self.resize(x1, [int(x_h*(1 + batch_ps[2]/2)), int(x_w*(1 + batch_ps[2]/2))])\n",
    "            x1 = self.resize(x1, [x_h, x_w])\n",
    "\n",
    "            result.append(x1)\n",
    "\n",
    "        x2 = tf.stack(result)\n",
    "        # 4d tensor -> 5d tensor\n",
    "        x3 = tf.reshape(x2, x_shape)\n",
    "        return x3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.0) # False\n",
    "mae = losses.MeanAbsoluteError()\n",
    "mse = tf.keras.metrics.MeanSquaredError()\n",
    "poisson = tf.keras.losses.Poisson()\n",
    "ada_loss = mse\n",
    "\n",
    "def dice_score_loss(y_true, y_pred):\n",
    "    numerator = 2. * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    return tf.reduce_mean(1 - numerator / denominator)\n",
    "\n",
    "def get_gene_loss(fake_output, real_output, fake_disc):\n",
    "    l1_loss = mae(real_output, fake_output)\n",
    "    gene_loss = bce(tf.ones_like(fake_disc), fake_disc)\n",
    "    return gene_loss, l1_loss\n",
    "\n",
    "def get_disc_loss(fake_disc, real_disc):\n",
    "    return bce(tf.zeros_like(fake_disc), fake_disc) + bce(tf.ones_like(real_disc), real_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_learning_rate = CustomSchedule(d_model=64, warmup_steps=5000)\n",
    "# disc_learning_rate = CustomSchedule(d_model=64, warmup_steps=5000)\n",
    "# gene_opt = optimizers.Adam(gene_learning_rate, beta_1=.5, beta_2=.999)\n",
    "# disc_opt = optimizers.Adam(disc_learning_rate, beta_1=.5, beta_2=.999)\n",
    "\n",
    "gene_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)\n",
    "disc_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = EncoderDecoderGenerator(blk_cnt=enc_blk_count)\n",
    "discriminator = Discriminator(blk_cnt=disc_blk_count)\n",
    "ada = ADA()\n",
    "\n",
    "generator.get_summary()\n",
    "discriminator.get_summary()\n",
    "\n",
    "# plot_model(discriminator, show_shapes=True, show_layer_names=True, expand_nested=True)\n",
    "\n",
    "history = {'tgen_loss':[], 'tdisc_loss':[], 'tl1_loss':[], 'vgen_loss':[], 'vdisc_loss':[], 'vl1_loss':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' gan model(train step)을 사용하지 않고 학습할때  '''\n",
    "\n",
    "# generator.compile(\n",
    "#     loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),\n",
    "# )\n",
    "\n",
    "# early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "# reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# generator.fit(\n",
    "#     tdgen,\n",
    "#     batch_size=batch_size,\n",
    "#     epochs=EPOCHS,\n",
    "#     validation_data=vdgen,\n",
    "#     callbacks=[early_stopping, reduce_lr],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(prefix='lstm_only_500'):\n",
    "    save_path = os.path.join(cfg.MODEL_SAVE_PATH, prefix)\n",
    "#     generator.lstms.load_weights(os.path.join(save_path, f\"lstm_{prefix}\"))\n",
    "    generator.encoder.load_weights(os.path.join(save_path, f\"encoder_{prefix}\"))\n",
    "    generator.decoder.load_weights(os.path.join(save_path, f\"decoder_{prefix}\"))\n",
    "\n",
    "    discriminator.load_weights(os.path.join(save_path, f\"disc_{prefix}\"))\n",
    "    \n",
    "    hist_file = os.path.join(save_path, f\"history_{prefix}.pic\")\n",
    "\n",
    "    with open(file=hist_file, mode='rb') as f:\n",
    "        loaded_history = pickle.load(f)\n",
    "    \n",
    "    print(f'{prefix} loaded...')\n",
    "    return loaded_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all(prefix='base_200'):\n",
    "    save_path = os.path.join(cfg.MODEL_SAVE_PATH, prefix)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    \n",
    "#     generator.lstms.save_weights(os.path.join(save_path, f\"lstm_{prefix}\"))\n",
    "    generator.encoder.save_weights(os.path.join(save_path, f\"encoder_{prefix}\"))\n",
    "    generator.decoder.save_weights(os.path.join(save_path, f\"decoder_{prefix}\"))\n",
    "\n",
    "    discriminator.save_weights(os.path.join(save_path, f\"disc_{prefix}\"))\n",
    "\n",
    "    hist_file = os.path.join(save_path, f\"history_{prefix}.pic\")\n",
    "    with open(file=hist_file, mode='wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "        \n",
    "    print(f'{prefix} saved...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_load_preload:\n",
    "    try:\n",
    "        history = load_all(prefix=save_load_prefix)\n",
    "    except:\n",
    "        print('preload weight failed !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def train_step(sketch, label, idx):\n",
    "    with tf.GradientTape() as gene_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generator 예측\n",
    "        fake_label = generator(sketch, training=True)\n",
    "        \n",
    "        # Discriminator 예측\n",
    "        fake_all_label = tf.keras.layers.Add()([fake_label, sketch[... , 1:]])\n",
    "        sketch_all_label = tf.keras.layers.Add()([sketch[... , :1], sketch[... , 1:]])\n",
    "        all_label = tf.keras.layers.Add()([label, sketch[... , 1:]])\n",
    "\n",
    "        fake_disc = discriminator(sketch_all_label, fake_all_label, training=True)\n",
    "        real_disc = discriminator(sketch_all_label, all_label, training=True)\n",
    "\n",
    "        # Generator 손실 계산\n",
    "        gene_loss, l1_loss = get_gene_loss(fake_label, label, fake_disc)\n",
    "        gene_total_loss = gene_loss + (train_lamda * l1_loss) ## <===== L1 손실 반영 λ=100\n",
    "\n",
    "        # Discrminator 손실 계산\n",
    "        disc_loss = get_disc_loss(fake_disc, real_disc)\n",
    "        \n",
    "        if use_ada and random.random() < ada_p:\n",
    "            # Discriminator aug 예측\n",
    "            ada.unlock()\n",
    "            fake_aug = ada(fake_label)\n",
    "            ada.lock()\n",
    "            sketch_aug = ada(sketch[... , :1])\n",
    "            sketch_all_aug = ada(sketch[... , 1:])\n",
    "            label_aug = ada(label)\n",
    "\n",
    "            fake_aug_all_label = tf.keras.layers.Add()([fake_aug, sketch_all_aug])\n",
    "            sketch_aug_all_label = tf.keras.layers.Add()([sketch_aug, sketch_all_aug])\n",
    "            aug_all_label = tf.keras.layers.Add()([label_aug, sketch_all_aug])\n",
    "\n",
    "            fake_aug_disc = discriminator(sketch_aug_all_label, fake_aug_all_label, training=False)\n",
    "            real_aug_disc = discriminator(sketch_aug_all_label, aug_all_label, training=False)\n",
    "\n",
    "            fake_aug_loss = ada_loss(fake_aug_disc, fake_disc)\n",
    "            real_aug_loss = ada_loss(real_aug_disc, real_disc)\n",
    "            \n",
    "            disc_total_loss = disc_loss + fake_aug_loss*ada_lamda1 + real_aug_loss*ada_lamda2\n",
    "\n",
    "            #tf.print(disc_loss, fake_aug_loss, real_aug_loss, disc_total_loss)\n",
    "        else:\n",
    "            disc_total_loss = disc_loss\n",
    "                \n",
    "    gene_gradient = gene_tape.gradient(gene_total_loss, generator.trainable_variables)\n",
    "    disc_gradient = disc_tape.gradient(disc_total_loss, discriminator.trainable_variables)\n",
    "\n",
    "    gene_opt.apply_gradients(zip(gene_gradient, generator.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(disc_gradient, discriminator.trainable_variables))\n",
    "    # disc_opt.apply_gradients(zip(disc_gradient, discriminator.trainable_variables))\n",
    "    return gene_loss, l1_loss, disc_total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(sketch, label):\n",
    "    # Generator 예측\n",
    "    fake_label = generator(sketch, training=False)\n",
    "\n",
    "    # Discriminator 예측\n",
    "    fake_disc = discriminator(sketch[... , :1], fake_label, training=False)\n",
    "    real_disc = discriminator(sketch[... , :1], label, training=False)\n",
    "\n",
    "    # Generator 손실 계산\n",
    "    gene_loss, l1_loss = get_gene_loss(fake_label, label, fake_disc)\n",
    "    gene_total_loss = gene_loss + (100 * l1_loss) ## <===== L1 손실 반영 λ=100\n",
    "\n",
    "    # Discrminator 손실 계산\n",
    "    disc_loss = get_disc_loss(fake_disc, real_disc)\n",
    "\n",
    "    return gene_loss, l1_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(vdgen)\n",
    "\n",
    "def show_predicts(cnt=3, save_path=\"\"):\n",
    "    # dataset중 첫번째만 뽑아서 예측에 입력\n",
    "    try:\n",
    "        x, y = next(it)\n",
    "    except Exception as e:\n",
    "        it = iter(vdgen)\n",
    "        x, y = next(it)\n",
    "\n",
    "    # 연속 예측한 이미지 3개 표시.\n",
    "    frame_cnt = x.shape[1]\n",
    "    in_x = x[:1, :-cnt+1, :, :, :]\n",
    "    in_y = y[:1, :, :, :, :]\n",
    "\n",
    "    for i in range(cnt):\n",
    "        pred = generator(in_x)\n",
    "        \n",
    "        if input_channel == 2:\n",
    "            img_ary = in_x[:, -1:, :, :, 1:]\n",
    "            pred_img = pred[:, -1:, :, :, :]\n",
    "            re_in = np.append(pred_img, img_ary, axis=4)\n",
    "            in_x = np.append(in_x, re_in, axis=1)\n",
    "        else:\n",
    "            in_x = np.append(in_x, pred[:, -1:, :, :, :], axis=1)\n",
    "\n",
    "    show_cnt = -1 * (cnt + 1)\n",
    "    if input_channel == 2:\n",
    "        show_imgs([in_x[:, show_cnt:], in_x[:, show_cnt:], y[:, show_cnt:]], save_path=save_path, channel=2)\n",
    "    else:\n",
    "        show_imgs([in_x[:, show_cnt:], y[:, show_cnt:]], save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"================================= config =================================\")\n",
    "print(f\"img size : {img_w}x{img_h}\")\n",
    "print(f\"data : ({data_seq_type}, {data_label_type}, {time_steps}frames), stacked:{stakced}, overlap:{overlap}, fill_box : {fill_box}\")\n",
    "print(f\"enc_blk : {enc_blk_count}, disc_blk : {disc_blk_count}, use_conv2n1 : {use_conv2n1} \")\n",
    "print(f\"ada : {use_ada}, ada_p : {ada_p}, ada_lamda : {ada_lamda1},{ada_lamda2} \")\n",
    "print(\"==========================================================================\\n\")\n",
    "\n",
    "# train_lamda = 100\n",
    "# ada_lamda1 = 10\n",
    "# ada_lamda2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 1000\n",
    "\n",
    "tit = iter(tdgen)\n",
    "vit = iter(vdgen)\n",
    "\n",
    "train_step_cnt = 5\n",
    "val_step_cnt = 1\n",
    "\n",
    "tg_loss, tl1_loss, td_loss = 0., 0., 0. \n",
    "vg_loss, vl1_loss, vd_loss = 0., 0., 0. \n",
    "best_total_loss = 10000\n",
    "\n",
    "print(f\"train started (batch: {batch_size}, epoch: {EPOCHS}, tstep:{train_step_cnt}, vstep:{val_step_cnt})\")\n",
    "\n",
    "batch_start = time()\n",
    "img_idx = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    # train loop\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    l1_losses = []\n",
    "    for loop in range(train_step_cnt):\n",
    "\n",
    "        print(f\"\\rT {epoch + 1:4d} {loop+1:3d}\", end=\"\")\n",
    "\n",
    "        try:\n",
    "            x, y = next(tit)\n",
    "        except Exception as e:\n",
    "            tit = iter(tdgen)\n",
    "            x, y = next(tit)\n",
    "\n",
    "        tg_loss, tl1_loss, td_loss = train_step(x, y, loop)\n",
    "\n",
    "        g_losses.append(tg_loss.numpy())\n",
    "        d_losses.append(td_loss.numpy())\n",
    "        l1_losses.append(tl1_loss.numpy())\n",
    "\n",
    "    tg_loss = np.average(np.array(g_losses))\n",
    "    td_loss = np.average(np.array(d_losses))\n",
    "    tl1_loss = np.average(np.array(l1_losses))\n",
    "    \n",
    "    history['tgen_loss'].append(tg_loss)\n",
    "    history['tdisc_loss'].append(td_loss)\n",
    "    history['tl1_loss'].append(tl1_loss)\n",
    "        \n",
    "    # validation loop\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    l1_losses = []\n",
    "    for loop in range(val_step_cnt):\n",
    "\n",
    "        print(f\"\\rV {epoch + 1:4d} {loop+1:3d}\", end=\"\")\n",
    "\n",
    "        try:\n",
    "            x, y = next(vit)\n",
    "        except Exception as e:\n",
    "            vit = iter(vdgen)\n",
    "            x, y = next(vit)\n",
    "\n",
    "        vg_loss, vl1_loss, vd_loss = val_step(x, y)\n",
    "\n",
    "        g_losses.append(vg_loss.numpy())\n",
    "        d_losses.append(vd_loss.numpy())\n",
    "        l1_losses.append(vl1_loss.numpy())\n",
    "\n",
    "    vg_loss = np.average(np.array(g_losses))\n",
    "    vd_loss = np.average(np.array(d_losses))\n",
    "    vl1_loss = np.average(np.array(l1_losses))\n",
    "\n",
    "    history['vgen_loss'].append(vg_loss)\n",
    "    history['vdisc_loss'].append(vd_loss)\n",
    "    history['vl1_loss'].append(vl1_loss)\n",
    "    \n",
    "    if save_load_interval > 0 and epoch > 0 and epoch % save_load_interval == 0:\n",
    "        save_all(prefix=save_load_prefix)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        img_save_path = os.path.join(cfg.MODEL_SAVE_PATH, save_load_prefix, \"imgs\")\n",
    "        if not os.path.exists(img_save_path):\n",
    "            os.mkdir(img_save_path)\n",
    "\n",
    "        img_save_file = os.path.join(img_save_path, f'result_{img_idx:04d}.png')\n",
    "        while os.path.exists(img_save_file):\n",
    "            img_idx += 1        \n",
    "            img_save_file = os.path.join(img_save_path, f'result_{img_idx:04d}.png')\n",
    "\n",
    "        show_predicts(save_path=img_save_file)\n",
    "        plot_history(history)\n",
    "\n",
    "    end = time()\n",
    "    elapsed_time = int(end-start)\n",
    "    \n",
    "    total_loss = tg_loss + vg_loss\n",
    "    if total_loss < best_total_loss:\n",
    "        best_total_loss = total_loss\n",
    "        prefix = save_load_prefix + \"_best\"\n",
    "        save_all(prefix=prefix)\n",
    "        \n",
    "\n",
    "    print(f\"\\r{epoch + 1:4d} {elapsed_time: 3d}s \",\n",
    "            f\"train g-loss:{tg_loss:.2f}  L1:{tl1_loss:.2f}  d-loss:{td_loss:.2f} \", \n",
    "            f\"val g-loss:{vg_loss:.2f}  L1:{vl1_loss:.2f}  d-loss:{vd_loss:.2f}\")\n",
    "\n",
    "batch_end = time()\n",
    "batch_time = int(batch_end-batch_start)\n",
    "\n",
    "print(f\"train completed ({batch_time//60}m {batch_time%60}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all(prefix=save_load_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = load_all(prefix=save_load_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)\n",
    "show_predicts()\n",
    "show_predicts()\n",
    "show_predicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6debceb626036820d184549e25d059a55b6b8771e25bc8133db281d329c34fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
